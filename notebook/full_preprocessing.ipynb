{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3ac6e84-1f2d-412f-ac6e-564c0809300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "from bioc import biocjson\n",
    "import pandas as pd\n",
    "import pypdf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a60fae1-af05-4bac-a378-5cbe532fad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions\n",
    "one_letter_aa_change = r'\\b([ARNDCQEGHILKMFPSTWYV])([1-9]+\\d*)(del|(?!\\1)[ARNDCQEGHILKMFPSTWYV])\\b'\n",
    "# three_letter_aa_change = r'\\b(?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)[1-9]+\\d*(?:ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VA|DEL)\\b'\n",
    "# three_letter_aa_change = r'\\b((?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL))(([1-9]+\\d*)(?!\\1)(?:ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)\\b'\n",
    "three_letter_aa_change = r'\\b((?:ALA|ARG|ASN|ASP|CYS|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL))([1-9]+\\d*)(?!(\\1))(ALA|ARG|ASN|ASP|CYS|DEL|GLN|GLU|GLY|HIS|ILE|LEU|LYS|MET|PHE|PRO|SER|THR|TRP|TYR|VAL)\\b'\n",
    "genome_change = r'\\bg\\.[ATGCU][1-9]+\\d*[ATGCU]\\b'\n",
    "genome_change_alt =  r'\\bg\\.[1-9]+\\d*[ATGCU]\\>[ATGCU]\\b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a057df6-55c6-4ab1-b0de-5d578ebfa4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dictionary(d):\n",
    "    print(\"size: \" + str(len(d)))\n",
    "    for key in d:\n",
    "        if d[key] is None:\n",
    "            print(\"None: \" + key)\n",
    "    \n",
    "        if d[key] == \"converting\":\n",
    "            print(\"Converting: \" + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "893c4392-450a-4238-bfcb-c630785ef263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(key):\n",
    "    doi_pattern = r'https:\\/\\/doi\\.org\\/[\\w/.-]+'\n",
    "    doi = re.search(doi_pattern, key)\n",
    "\n",
    "    if doi is not None:\n",
    "        file_name = key.split('doi.org/')[-1]\n",
    "    else:\n",
    "        key = key.split('https://')[-1]\n",
    "        file_name = key\n",
    "\n",
    "    # Replace . in DOI with -\n",
    "    file_name = file_name.replace(\".\", \"-\")\n",
    "    # Replace / in DOI with _\n",
    "    file_name = file_name.replace(\"/\", \"_\")\n",
    "    # file_name += \".pdf\"\n",
    "\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b5695-c5d9-47ff-b3e9-73fd05e7c202",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "62a0c1e1-7c2b-4c26-98a8-54bcec5cdf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load litcovid data\n",
    "with open('/home/david.yang1/autolit/litcovid/data/litcovid2BioCJSON') as f:\n",
    "    litcovid_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "021c6764-d144-4e33-b452-dea961f77b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all pokay data\n",
    "with open('../data/processed/pokay/data_bioc.txt') as file:\n",
    "    pokay_data = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b93d1c5-0548-4fcf-8128-28aff8e203ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokay publication data\n",
    "with open('../data/processed/pokay/publication_bioc.txt') as file:\n",
    "    publication_bioc= json.loads(file.read())\n",
    "\n",
    "publication_bioc = {k: v for k, v in publication_bioc.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f6f1f05-b8fd-4a00-9655-5e4fb7e7668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokay publication unk data\n",
    "with open('../data/processed/pokay/publication_unk_bioc.txt') as file:\n",
    "    publication_unk_bioc= json.loads(file.read())\n",
    "\n",
    "publication_unk_bioc = {k: v for k, v in publication_unk_bioc.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "668be64e-4ee2-48b5-94ed-6ed5bd824690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokay rxiv data\n",
    "# with open('rxiv_bioc.txt') as file:\n",
    "#         rxiv_bioc= json.loads(file.read())\n",
    "\n",
    "with open('../data/processed/pokay/rxiv_bioc.txt') as file:\n",
    "    rxiv_bioc= json.loads(file.read())\n",
    "    \n",
    "rxiv_bioc = {k: v for k, v in rxiv_bioc.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3a50f712-ca64-448c-a144-e28b338b2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokay rxiv unknown data\n",
    "with open('../data/processed/pokay/rxiv_unk_bioc.txt') as file:\n",
    "    rxiv_unk_bioc= json.loads(file.read())\n",
    "\n",
    "rxiv_unk_bioc = {k: v for k, v in rxiv_unk_bioc.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd6e94fd-8d8d-471a-817b-a53511100a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pokay grey literature\n",
    "with open('../data/processed/pokay/grey_bioc.txt') as file:\n",
    "    grey_bioc = json.loads(file.read())\n",
    "\n",
    "grey_bioc = {k: v for k, v in grey_bioc.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0cc07ca1-737e-42a9-b36b-463c0266a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 316\n",
      "None: https://doi.org/10.1016/S1473-3099\n",
      "None: https://doi.org/10.1016/s1473-3099\n",
      "None: https://doi.org/10.1002/jmv.26997\n",
      "None: https://doi.org/10.1080/23744235.2021.1977382\n",
      "None: https://doi.org/10.1002/jmv.27247\n",
      "None: https://doi.org/10.1016/S0140-6736\n",
      "None: https://doi.org/10.1073/pnas.1707304114\n",
      "None: https://doi.org/10.21203/rs.3.rs-318392/v1\n",
      "None: https://www.researchgate.net/publication/348943694_The_mutation_P681H_in_the_B117_variant_of_SARS-CoV-2_probably_enhances_viral_entry_and_replication\n",
      "None: https://observablehq.com/@aglucaci/sc2-omicron\n",
      "None: https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/961042/S1095_NERVTAG_update_note_on_B.1.1.7_severity_20210211.pdf\n",
      "None: https://doi.org/10.47326/ocsat.dashboard.2021.1.0\n",
      "None: https://www.covid19genomics.dk/2021-05-08_data-overview.html#b1525\n",
      "None: https://drive.google.com/file/d/1CuxmNYj5cpIuxWXhjjVmuDqntxXwlfXQ/view\n",
      "None: https://www.moh.gov.sg/news-highlights/details/3-new-cases-of-locally-transmitted-covid-19-infection-28apr2021-update\n",
      "None: https://mg.co.za/coronavirus-essentials/2021-03-24-single-dose-jj-janssen-covid-19-vaccine-hopes-to-speed-up-sas-vaccination-programme/\n",
      "None: https://github.com/cov-lineages/pango-designation/issues/4\n"
     ]
    }
   ],
   "source": [
    "check_dictionary(pokay_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401de86-0735-42a7-ae76-f6cecdb28997",
   "metadata": {},
   "source": [
    "# Basic filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8559315e-4919-4971-af5b-2d522c59814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by REGEX\n",
    "# count = 0\n",
    "# filtered_papers = []\n",
    "\n",
    "# for paper in litcovid_data[1]:\n",
    "    \n",
    "#     try:\n",
    "#         passage = paper[\"passages\"]\n",
    "#     except:\n",
    "#         continue\n",
    "    \n",
    "#     text = \"\"\n",
    "\n",
    "#     for section in passage:\n",
    "#         # print(\" \")\n",
    "#         # print(section) \n",
    "#         try:\n",
    "#             text += section['text']\n",
    "#         except:\n",
    "#             pass\n",
    "\n",
    "#     mutations = []\n",
    "#     mutations += [\"\".join(x) for x in re.findall(one_letter_aa_change, text, re.IGNORECASE)]\n",
    "#     mutations += [\"\".join(x) for x in re.findall(three_letter_aa_change, text, re.IGNORECASE)]\n",
    "#     mutations += re.findall(genome_change, text, re.IGNORECASE)\n",
    "#     mutations += re.findall(genome_change_alt, text, re.IGNORECASE)\n",
    "#     mutations = set(mutations)\n",
    "\n",
    "#     if len(mutations) > 0:\n",
    "#         filtered_papers.append(paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "317c23b9-c62b-4703-b5d9-58b6e962539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('filtered_papers.txt', 'w') as file:\n",
    "#      file.write(json.dumps(filtered_papers))\n",
    "\n",
    "with open('filtered_papers.txt') as file:\n",
    "        filtered_papers = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "edb5b999-738e-4e67-a37e-941a992ebafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove papers that are in pokay database\n",
    "\n",
    "def related_paper(paper):\n",
    "    try:\n",
    "        doi = paper[\"passages\"][0]['infons']['article-id_doi']\n",
    "        \n",
    "        if doi in pokay_data:\n",
    "            return True\n",
    "            \n",
    "    except:\n",
    "        return False\n",
    "\n",
    "    return False\n",
    "\n",
    "filtered_papers_copy = [x for x in filtered_papers if not related_paper(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "77ec9620-569d-4346-8111-0eef3b55dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by date. Only grab papers from 2021 to guarantee\n",
    "\n",
    "before_date_filtered_papers = []\n",
    "\n",
    "for paper in filtered_papers_copy:  \n",
    "    try:\n",
    "        year = paper[\"year\"]\n",
    "        if int(year) <= 2021:\n",
    "            before_date_filtered_papers.append(paper)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc91cd-d6b8-4e04-83ef-5a86ba123402",
   "metadata": {},
   "source": [
    "# Sample from dataset to make training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "67b0692c-3897-44d4-b5fc-4f5d28d15b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grab subsample from data\n",
    "\n",
    "def subset_sample(original, n):\n",
    "    sub = []\n",
    "    df = copy.deepcopy(original)\n",
    "    random.shuffle(df)\n",
    "    \n",
    "    for i in range(n):\n",
    "        entry = df.pop(-1)\n",
    "        sub.append(entry)\n",
    "\n",
    "    return df, sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57686aa-1bc6-4e94-ab4f-724bd286854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "litcovid, train_data = subset_sample(before_date_filtered_papers, len(pokay_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f95a8-1289-41d3-8066-e6b1eaa8d733",
   "metadata": {},
   "source": [
    "# Extract text portions from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e8c71566-8dea-4120-9493-850674727025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract from training data (litcovid portion)\n",
    "def litcovid_text_extract(data):\n",
    "    count = 0\n",
    "    out = []\n",
    "    for paper in data:\n",
    "        try:\n",
    "            passage = paper[\"passages\"]\n",
    "        except:\n",
    "            count += 1\n",
    "            continue\n",
    "\n",
    "        text = \"\"\n",
    "        \n",
    "        for section in passage:\n",
    "            try:\n",
    "                text += section['text']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        out.append(text)\n",
    "        \n",
    "    # print(count)\n",
    "    return out\n",
    "\n",
    "train_data_text = litcovid_text_extract(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae110d1d-12c5-4923-9bdd-ed5841bd7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to un-nest data\n",
    "\n",
    "def extract_nested_elements(input_string):\n",
    "    elements = []\n",
    "    start = 0\n",
    "    brace_count = 0\n",
    "    inside_element = False\n",
    "\n",
    "    for i, char in enumerate(input_string):\n",
    "        if char == '{':\n",
    "            if brace_count == 0:\n",
    "                start = i\n",
    "                inside_element = True\n",
    "            brace_count += 1\n",
    "        elif char == '}':\n",
    "            brace_count -= 1\n",
    "            if brace_count == 0 and inside_element:\n",
    "                elements.append(input_string[start:i+1])\n",
    "                inside_element = False\n",
    "\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1884c1b-1b66-4dcf-9a5b-ba9c9b5f0257",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Archived functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2942faa6-6b3a-4e85-8d95-bd13b5e94792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text of papers obtained from Pubtator API\n",
    "# def pubtator_text_extract(data):\n",
    "#     out_text = []\n",
    "#     count = 0\n",
    "\n",
    "#     for paper in data.values():\n",
    "#         text = \"\"\n",
    "\n",
    "#         paper = paper[1:-1]\n",
    "\n",
    "#         try:\n",
    "#             bioc_list = extract_nested_elements(paper)\n",
    "            \n",
    "#             bioc_collection = biocjson.loads(bioc_list[-1])\n",
    "            \n",
    "#         except:\n",
    "#             count += 1\n",
    "#             continue\n",
    "\n",
    "#         for document in bioc_collection.documents:    \n",
    "#             for passage in document.passages:\n",
    "#                 try:\n",
    "#                     text += passage.text\n",
    "#                 except:\n",
    "#                     print(passage)\n",
    "#                     pass\n",
    "       \n",
    "#         if text == \"\":\n",
    "#             count += 1\n",
    "#             continue\n",
    "    \n",
    "#         out_text.append(text)\n",
    "\n",
    "#     # print(count)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87719fa-6de1-4604-b7cb-9e8f00f14b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from paper obtained with JATS XML\n",
    "# def jats_text_extract(data):\n",
    "#     out_text = []\n",
    "#     count = 0\n",
    "#     error = \"\"\n",
    "    \n",
    "#     for paper in data.values():\n",
    "#         text = \"\"\n",
    "    \n",
    "#         try:\n",
    "#             paper_copy = paper[1:-1]\n",
    "#             bioc_collection = biocjson.loads(paper_copy)\n",
    "    \n",
    "#         except:\n",
    "#             try:\n",
    "#                 bioc_collection = biocjson.loads(paper)\n",
    "#             except:\n",
    "#                 count+=1\n",
    "#                 print(count)\n",
    "#                 error = paper\n",
    "#                 continue\n",
    "        \n",
    "            \n",
    "#         for document in bioc_collection.documents:    \n",
    "#             for passage in document.passages:\n",
    "#                 try:\n",
    "#                     text += passage.text\n",
    "#                 except:\n",
    "#                     print(passage)\n",
    "#                     pass\n",
    "    \n",
    "#         if text == \"\":\n",
    "#             count += 1\n",
    "#             continue\n",
    "    \n",
    "#         out_text.append(text)\n",
    "#     return out_text\n",
    "#         # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38d03107-e405-454e-854e-0c3082e7b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pdf_text_extract(data):\n",
    "#     out_text = []\n",
    "#     count = 0\n",
    "    \n",
    "#     for paper in data.values():\n",
    "#         text = \"\"\n",
    "\n",
    "#         try:\n",
    "#             bioc_collection = biocjson.loads(paper)\n",
    "    \n",
    "#         except:\n",
    "#             print(\"failed to load bioc collection\")\n",
    "            \n",
    "#         for document in bioc_collection.documents:    \n",
    "#             for passage in document.passages:\n",
    "#                 try:\n",
    "#                     text += passage.text\n",
    "#                 except:\n",
    "#                     print(passage)\n",
    "#                     pass\n",
    "    \n",
    "#         if text == \"\":\n",
    "#             count += 1\n",
    "#             continue\n",
    "    \n",
    "#         out_text.append(text)\n",
    "#     return out_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416a00b3-f974-48d3-8c33-46c6b48d20d6",
   "metadata": {},
   "source": [
    "# Break into subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12636ac3-e851-4338-b06e-610a76512f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pubtator\n",
    "def pubtator_extract(paper):\n",
    "    text = \"\"\n",
    "    paper = paper[1:-1]\n",
    "\n",
    "    try:\n",
    "        bioc_list = extract_nested_elements(paper)\n",
    "        \n",
    "        bioc_collection = biocjson.loads(bioc_list[-1])\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "            except:\n",
    "                print(passage)\n",
    "                pass\n",
    "   \n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af73e7be-0286-461a-a0b3-2c54745a5cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JATS\n",
    "def jats_extract(paper):\n",
    "    text = \"\"\n",
    "    \n",
    "    try:\n",
    "        paper_copy = paper[1:-1]\n",
    "        bioc_collection = biocjson.loads(paper_copy)\n",
    "\n",
    "    except:\n",
    "        try:\n",
    "            bioc_collection = biocjson.loads(paper)\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "980563a8-b7b9-4251-a98a-ad806a68f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF\n",
    "def pdf_extract(data):\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        bioc_collection = biocjson.loads(paper)\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "        \n",
    "    for document in bioc_collection.documents:    \n",
    "        for passage in document.passages:\n",
    "            try:\n",
    "                text += passage.text\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if text == \"\":\n",
    "        return None\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "56def181-0df0-4eed-9964-e08de7e17f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/10-21203_rs-3-rs-318392_v1.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/www-researchgate-net_publication_348943694_The_mutation_P681H_in_the_B117_variant_of_SARS-CoV-2_probably_enhances_viral_entry_and_replication.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/observablehq-com_@aglucaci_sc2-omicron.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/assets-publishing-service-gov-uk_government_uploads_system_uploads_attachment_data_file_961042_S1095_NERVTAG_update_note_on_B-1-1-7_severity_20210211-pdf.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/10-47326_ocsat-dashboard-2021-1-0.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/www-covid19genomics-dk_2021-05-08_data-overview-html#b1525.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/drive-google-com_file_d_1CuxmNYj5cpIuxWXhjjVmuDqntxXwlfXQ_view.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/www-moh-gov-sg_news-highlights_details_3-new-cases-of-locally-transmitted-covid-19-infection-28apr2021-update.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/mg-co-za_coronavirus-essentials_2021-03-24-single-dose-jj-janssen-covid-19-vaccine-hopes-to-speed-up-sas-vaccination-programme_.pdf\n",
      "/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/github-com_cov-lineages_pango-designation_issues_4.pdf\n"
     ]
    }
   ],
   "source": [
    "# script to iterate through\n",
    "pokay_text = []\n",
    "\n",
    "for key in pokay_data:\n",
    "    paper = pokay_data[key]\n",
    "    text_extracted = False\n",
    "    text = \"\"\n",
    "    \n",
    "    if paper is not None:\n",
    "        # Try to extract as pubtator\n",
    "        try:\n",
    "            text = pubtator_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if text_extracted:\n",
    "            continue\n",
    "\n",
    "        # Try to extract as JATS\n",
    "        try:\n",
    "            text = jats_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if text_extracted:\n",
    "            continue\n",
    "\n",
    "        # Try to extract as PDF\n",
    "        try:\n",
    "            text = pdf_extract(paper)\n",
    "\n",
    "            if text is not None:\n",
    "                text_extracted = True\n",
    "                pokay_text.append(text)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    else:\n",
    "        file = get_file_name(key)\n",
    "        file = \"/home/david.yang1/autolit/viriation/data/raw/pdf/unconverted/\" + file + \".pdf\"\n",
    "        isExist = os.path.exists(file) \n",
    "        if isExist:\n",
    "            print(file)\n",
    "            reader = pypdf.PdfReader(file)\n",
    "    \n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text()\n",
    "    \n",
    "            if text != \"\":\n",
    "                pokay_text.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0c8d1315-4f05-40b7-a85c-9a458ff97d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pokay_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "298f7211-2abd-4555-bf9c-8ba06e3891fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rxiv_text = jats_text_extract(rxiv_bioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1f118d5-4147-4dad-99f6-43e5ef5c6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication_text = pubtator_text_extract(publication_bioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef959b66-9087-4449-b054-de260f19697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rxiv_unk_text = jats_text_extract(rxiv_unk_bioc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d05b22f7-5981-4522-abe1-79e3928dc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# publication_unk_text = pdf_text_extract(publication_unk_bioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4375b9fa-3045-45d2-8f5d-dd6bc940d0ef",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969f0e2-18d7-4249-b065-2fb6e8f10df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bricken.co/nlp_disaster_tweets_2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18b943-f6ac-4ad7-884e-3015931aa49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ad9e380-6cec-43ee-a759-70341fa6553a",
   "metadata": {},
   "source": [
    "# Create train, evaluation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0421b9b9-041f-4a13-9929-0e41c9c74594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train_data_text, columns=[\"text\"])\n",
    "df[\"label\"] = 0\n",
    "\n",
    "df_2 = pd.DataFrame(pokay_text, columns=[\"text\"])\n",
    "df_2[\"label\"] = 1\n",
    "\n",
    "df = pd.concat([df, df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e8dfb2b8-8d36-4632-906a-dcb72cb4b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bn_pub_dataset_3.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
